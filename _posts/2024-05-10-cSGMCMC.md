---
layout: single
title: 'CYCLICAL STOCHASTIC GRADIENT MCMC FOR BAYESIAN DEEP LEARNING'
categories: deep_learning
tag: [딥러닝, 불확실성, python]
author_profile: false
sidebar:
    nav: "docs"
use_math: true
---


### 목차

- Introduction
- Preliminaries:SG-MCMC
- Cyclical SG-MCMC
- Theoretical Analysis
- Experiment
- Summary

석사 졸업 논문 초고 작성하다 흥미로운 내용이 있어 해당 논문을 공부해보려 한다. 

## 1. Introduction

심층신경망의 가중치의 사후분포는 대부분의 경우 고차원이며 multi-modal(convex하지 않고 여러개의 봉우리가 존재)인 경우가 많다. 그래서 이 사후분포로부터 가중치를 추출하려 하면 국소적인 최대 혹은 최소지점에 갇혀 다른 부분을 표본추출 하지 못하는 경우가 생긴다. 이를 해결하기 위해선 학습률을 크게 잡아야하지만, SGLD를 포함한 확률적 몬테카를로 방법에서는 반복을 진행할 때마다 학습률을 작게해야 수렴성이 보장되기 때문에 지속적으로 학습률을 크게 하기 어렵다는 문제점이 있다.

해당 논문은 이를 해결하기 위해 Cyclical learning rate scheduler를 사용하는 방법을 제안한다.

## 2. Preliminaries:SG-MCMC

SG-MCMC에는 크게 두가지 방법이 있는데 하나는 해밀토니안 몬테카를로를 바탕으로한 SG-HMC와 다른 하나는 랑쥬빈 몬테카를로를 바탕으로한 SG-SGLD가 있다. SG-SGLD에 대해서는 이전에 다룬 포스팅이 있으니 해당 내용 참고해주면 될 것 같다. 핵심만 요약해서 말하면 사후분포로터 표본을 추출하는데 이 경우 전체 데이터에 대한 가능도를 사용하면 너무 계산량이 많아지므로 sgd의 방법론을 받아드려, mini-batch로 데이터를 나눠 이로부터 표본을 추출하는 방법론을 칭한다.

이 때 추출된 표본이 사후분포로 수렴하기 위해서는 다음 가정을 만족해야 한다.

$\bold{Assumption1.}$ The step size $\{\alpha_{k} \}$ are decreasing, i.e., $0<\alpha_{k+1}< \alpha_{k}$, with $1) \sum_{k=1}^{\infty} \alpha_{k} = \infty ; \text{and} 2)  \sum_{k=1}^{\infty} \alpha_{k}^{2} < \infty$.

## 3. Cyclical SG-MCMC

위 처럼 학습률이 작아지는데 local mode에 갇힌 경우 여기서 벗어나기 위해서는 많은 수의 반복이 필요하다. 즉 다시말해 계산량이 많아지는 문제가 생긴다. 이를 해결하기 위해 해당 논문의 저자는 Cyclical learning rate scheduler를 다음과 같이 코사인 함수를 이용해 제시한다. 

$k$번째 반복의 학습률을 다음과 같이 정의한다.

$$
\begin{align}
\alpha_{k} = \frac{\alpha_{0}}{2} \left[ \cos \left( \frac{\pi \text{ mod}(k-1, K/M)}{K/M} \right) + 1\right],
\end{align}
$$

여기서 $M$ 은 한 주기안에 속하는 반복의 횟수이고, $K$는 전체 반복 횟수를 의미한다. 

흥미로웠던점은 여기서 각 주기마다 burn-in을 적용한다는 점이었다. 각 주기안에서 학습률이 큰 초기에는 사후분포에서 확률밀도가 높은 곳을 찾아가는 단계(Exploration Stage), 그리고 어느정도 반복이 진행되 새로운 local mode를 찾아내고 학습률이 충분히 작아진 다음에는 그 mode를 구체화해 표본을 추출하는 단계(Sampling Stage) 이 두 단계로 나눠서 반복해 표본추출을 진행하는게 가장 흥미로웠다.

이를 Epoch($k$)에 대한 그래프로 나타내면 다음과 같다.

![png](/images/cSGMCMC-files/csgmcmc1.png)


전체 과정을 알고리즘으로 쓰면 다음과 같다.


$\bold{Algorithm\,\,1}$ Cyclical SG-MCMC

$\bold{input:}$ The initial stepsize $\alpha_{0}$, number of cycles $M$, number of training iterations $K$ and proportion of exploration stage $\beta$.

$\quad \bold{for} \text{ k=1:K} \text{ do}$ 

$\qquad \alpha \leftarrow \alpha_{k}$ according to Eq (1).

$\qquad \bold{if} \, \, \frac{ \text{ mod}(k-1, K/M)}{K/M} < \beta \text{ }\bold{then}$

$\qquad \quad \% \text{ Exlploration stage}$

$\qquad \quad \theta \leftarrow \theta -\alpha \nabla \tilde{U}_{k} (\theta)$

$\qquad \bold{else}$

$\qquad \quad \% \text{ Sampling stage}$

$\qquad \quad \text{ Collect samples using SG-MCMC methods}$

$\bold{Output:} \text{ Samples } \{\theta_{k} \}$ 

이전에는 multi-modal분포로 부터 표본추출을 하기 위해서는 초기값을 여러개로 설정해서 여러개의 마코프체인을 추출하는 방법을 사용했었다. 이런 경우 마코프 체인을 $m$개를 추출한다고 하면 체인의 개수 * 체인의 길이 만큼의 계산량이 필요했지만, 위 방법을 사용하면 하나의 체인만으로   multi-modal분포로 부터 표본추출이 가능하기 때문에 계산상에서 이점이 있다.

## 4. Optimization

우리의 목표는 이제 

$$
\begin{align}
\argmin_{\theta} - \int \log f(Y | X, \omega) q_{\theta}(\omega) d \omega + KL(q_{\theta}(\omega), p(\omega))
\end{align}
$$

인 Variational parameter인 $\theta$를 찾는 것인데, 실제 이것을 바로 계산하기엔 어려움이 따른다. 그래서 몇 가지 근사와 계산을 통해 (2)식을 변형하고 그것을 최소로 하는 $\theta$가 어떻게 Dropout으로 구해진 weight와 동할한지 알아보도록 하자.

### 4.1. Monte Calro Approximation

먼저 $\int \log f(Y | X, \omega) q_{\theta}(\omega) d \omega$ 이 항에 대해서 생각해보자. 실제 저 식들은 알고있지만 문제는 저걸 closed form으로 계산하고 적분하는게 사실상 불가능에 가깝다. 그래서 이걸 실제 수학적으로 푸는게 아닌 Monte Calro 적용해 $q_{\theta}(\omega)$ 에서 표본추출해 계산한다. 일단 각 데이터셋이 모두 독립이므로 이는 다음과 같다.

$$
\int \log f(Y | X, \omega) q_{\theta}(\omega) d \omega = \sum_{i = 1}^{N} \int \log f(y_{i} \mid x_{i}, \omega) q_{\theta}(\omega) d \omega
$$

이제 $\int \log f(y_{i} \mid x_{i}, \omega) q_{\theta}(\omega) d \omega$ 를 근사하기 위해 Monte Calro를 사용한다. 다만 이 논문에서 제일 이해가 되지 않는 부분 중 한 곳이 여기인데 보통 Monte Calro를 사용한다하면 분포로 부터 여려개의 표본을 추출해 그것의 표본평균으로 적분(모평균)을 근사하는데 이 경우 각각의 인덱스 $i$에 대하여 "하나의" 표본만 추출해 적분을 근사했다. 그래서 위 식을 다음과 같이 근사한다.

$$
\begin{align}
\int \log f(Y | X, \omega) q_{\theta}(\omega) d \omega &= \sum_{i = 1}^{N} \int \log f(y_{i} \mid x_{i}, \omega) q_{\theta}(\omega) d \omega \\
&\approx \sum_{i = 1}^{N} \log f(y_{i} \mid x_{i}, \omega_{i}) \text{ where } \omega_{i} \sim q_{\theta}(\omega)
\end{align}
$$

위에서도 언급했듯 내 생각에는 (4)에서 보다 정확히 근사하기 위해선 합의 합꼴로 나태내져야 맞다 생각하는데 여기선 이미 합형태이고 각 index에서 각각이 $\omega_{i}$를 추출해 그것의 합을 구하는 것이니 충분하다 생각했는지 하나의 표본만 추출해 의아함이 남는다. 

여하튼 여기서 만약 우리가 가정한것처럼 회귀문제이면 저 log-likelyhood는 $-MSE$와 비례할 것이고 그렇지 않고 분류문제이면 $-CE$와 비례할 것이다. 그래서 이 식을 (2)에 대입한다면 DNN에서 loss function의 형태가 나오게 된다.

### 4.2. More Calculation

이 파트는 (2)식에서 $KL(q_{\theta}(\omega), p(\omega))$ 이것을 계산하고 근사해 변형하는 것에 대해서 다룬다.

다만 이 과정이 길고 지루하며 통계적 계산능력을 요구하기 때문에 여기선 자세히 다루진 않고 결과만 쓰도록 하자. 만약 궁금한 사람이 있다면, (Gal, 2016)의 Appendix를 참고하자.

$KL(q_{\theta}(\omega), p(\omega))$은 다음과 같이 근사할 수 있다.

$$
\begin{align}
KL(q_{\theta}(\omega), p(\omega)) \approx \frac{p}{2} ||M_{1}||^{2} + \frac{p}{2} ||M_{2}||^{2}  + Constant
\end{align}
$$

### 4.3. Relationship with Dropout


(2),(4),(5)를 종합하면 결과적으로 우리가 구해야하는 값은 다음과 같다.

$$
\argmin_{\theta} \frac{\tau}{2} \sum_{i=1}^{N} ||y_{i} - \sigma(x_{i}W_{i1})W_{i2}||^{2} + \frac{p}{2} ||M_{1}||^{2} + \frac{p}{2} ||M_{2}||^{2} \text{ where } \omega_{i} \sim q_{\theta}(\omega)
$$

이 때 나누는 것은 최소가 되는 $\theta$를 구하는 것에 영향을 주지 않으므로 최적화 식을 $\frac{\tau}{2}$로 나누고, $\lambda = \frac{p}{\tau}$로 설정한 뒤 $W$안에 숨어 있는 $\sigma$를 0으로 극한을 보내면 다음 식을 얻을 수 있다.

$$
\begin{align}
    \argmin_{M_{1},M_{2}}\sum_{i=1}^{N} ||y_{i} - \sigma(x_{i}diag(z_{i1j})M_{1} )diag(z_{i2q})M_{2} ||^{2} + \lambda ||M_{1}||^{2} + \lambda ||M_{2}||^{2}    
\end{align}
$$
where,  $z_{i1j}, z_{i2q} \overset{iid}{\sim} bernoulli(p), j = 1,2,\cdots,Q ,\, q = 1,2,\cdots,K$.

이 식을 만족하는 $M_{1},M_{2}$는 DNN에서 Dropout을 사용해 얻어진 weight와 정확히 동일한 식이므로 해당 weight를 사용해 Variational parameter를 근사가능하다.

## 5. Inference

4장 까지의 내용을 통해 weight의 사후분포를 근사하는 Variational distribution을 Dropout DNN을 통해 구할 수 있단 걸 구했다. 그렇다면 이것을 어떻게 해야 Bayesian으로 해석 가능할까. 일반적인 Dropout DNN과의 차이는 과연 무엇일까? 그것은 바로 Inference 과정에서 발생한다. Training 시에는 똑같이 진행되지만 Dropout DNN에서는 inference 할 때 Dropout을 적용시키지 않고 한개의 고정된 출력값을 구하는 반면, MC-Dropout에서는 inference시에도 Dropout을 적용한다. 그에 따라 한개의 입력값에 대해 여러 출력값이 나올 수 있다.

쉽게 설명해 MC-Dropout은 한개의 입력값 $x$에 대해 inference를 진행할 때 Dropout을 적용한 여러번의 반복을 통해 여러 출력값 $y_{t}$를 얻고 이것의 평균으로 예측값을 얻어내고, 분산으로 모델 불확실성을 추정한다. 직관적으로 다음 그림을 참고하면 좋을 것 같다.

![png](/images/MCDropout_files/MC_dropout1.png)

다시 말해 $y \mid x$의 분포에서 표본추출하는 과정을 반복하는 것이다. 그리고 그 표본들을 이용해 분포의 통계량들을 추정할 수 있다. 저 표본들의 표본평균과 표본 분산이 실제 평균, 분산의 불편추정량으로 근사할 수 있다는걸 이론적으로 증명할 수 있으나 해당 포스팅의 범위를 넘는다 판단해 여기에 담지 않도록 하겠다. 관심있는 독자들은 (Gal, 2016)의 Appendix를 참고하자.

## 6. Summary

지금까지 MC-Dropout에 대해 정리해봤다. 사실 해당 논문에는 이 내용 의외에도 BNN이 Deep-GP로 수렴한다는 내용을 다뤄 보다 어렵지만, 내 생각에 그건 당장에 필요한 부분은 아닌 것 같아 굳이 다루지 아니 하였다. 의미있는 내용이지만 굳이 같은 논문에서 다룰만큼 잘 어우러지냐? 라고 하면 사실 나는 잘 모르겠더라. 처음 Bayesian neural network를 공부하려 했을때 "처음 공부하는 것이니 인용수가 제일 높은거 부터 읽어보자" 라고 생각해 읽게된 논문이다. 이때만 해도 논문 읽는게 익숙하던 때가 아니었어서 처음 읽을때 엄청 어렵고 해맸던 기억이 나는데 그게 벌써 1년하고도 6개월 전이다. 막상 나중에 선배한테 물어보니 다른 방법론들에 비해 성능이 안좋기 때문에 그렇게 많이 안 쓴다고 한다. 근데 왜 인용수가 높냐고 물어보니 성능이 안좋아 baseline으로 쓰기 좋기때문에 이곳 저곳에 많이 불려나가서 그렇다는데.... 그럼에도 한 번쯤은 정리 해둘 필요가 있을 것 같아 대략적인 내용은 정리 한 것 같다.

## 7. Reference

    1. Gal, Yarin, and Zoubin Ghahramani. "Dropout as a bayesian approximation: Representing model uncertainty in deep learning." international conference on machine learning. PMLR, 2016.